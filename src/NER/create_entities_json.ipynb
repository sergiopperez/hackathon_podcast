{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1shnZb2uafo56jVujryiXKovd8mrqDLUx","authorship_tag":"ABX9TyM0yAOVjSbRq1P2+BaT9R8U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Start installing openai:"],"metadata":{"id":"fPKHjoA8incv"}},{"cell_type":"code","source":["%pip install openai\n","import json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vbp_UIRmkFfE","executionInfo":{"status":"ok","timestamp":1680857757953,"user_tz":-60,"elapsed":11176,"user":{"displayName":"Sergio Perez","userId":"07187495172449483138"}},"outputId":"d91c3817-de15-4e59-875d-c9759522465d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openai\n","  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.8.2\n"]}]},{"cell_type":"markdown","source":["Define the prompt to pass to the OpenAI api to perform NER:\n"],"metadata":{"id":"5hIbtpr_o-lk"}},{"cell_type":"code","source":["PROMPT_TEMPLATE = \"\"\"\n","Perform name entity recognition in Spanish. The classes are books, films, videogames, songs, places, dates, topics, organizations and people. The output should follow the format:\n","\n","[{'class': 'people', 'text': \"name of the person\"}, {'class': 'books', 'start': 'name of the book}]\n","\n","Sentence: \n","\n","\"\"\"\n"," "],"metadata":{"id":"5cgopnS3ish-","executionInfo":{"status":"ok","timestamp":1680857786984,"user_tz":-60,"elapsed":234,"user":{"displayName":"Sergio Perez","userId":"07187495172449483138"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","Define a function to call the api of OpenAI:\n"],"metadata":{"id":"hrjje0jYraVF"}},{"cell_type":"code","source":["from json import loads\n","import os\n","import openai\n","\n","# set your api key as ENV, for example with Python: os.environ[\"OPENAI_API_KEY\"] = \"your api key\"\n","os.environ[\"OPENAI_API_KEY\"] = \"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\"\n","openai.api_key = os.getenv(\"OPENAI_API_KEY\") \n","\n","def classify(text):\n","    # build prompt with template and input\n","    prompt = f\"{PROMPT_TEMPLATE}\\n{text}\\n\"\n","    # use create completion template\n","    completion = openai.Completion.create(\n","      model=\"text-davinci-003\",\n","      prompt=prompt,\n","      temperature=0,\n","      max_tokens=512\n","    )\n","    # get first choice text\n","    json_response = completion[\"choices\"][0][\"text\"].strip()\n","\n","    return json_response"],"metadata":{"id":"7Q-eH5WBpKjl","executionInfo":{"status":"ok","timestamp":1680857791126,"user_tz":-60,"elapsed":1354,"user":{"displayName":"Sergio Perez","userId":"07187495172449483138"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Define the input and output folders and call the OpenAI api. For this part to work you need to create an account in https://platform.openai.com/. It is free and will give you 5$ to use the api and playground. Once you've created an account, "],"metadata":{"id":"pZEDaQ8M-A96"}},{"cell_type":"code","source":["\n","\n","# specify folder of input transcriptions\n","\n","transcription_folder = \"/content/drive/MyDrive/hackathon_podcast/data/NER/processed_transcription/\"\n","\n","# specify folder of output jsons\n","\n","json_folder = \"/content/drive/MyDrive/hackathon_podcast/data/NER/json_entity/\"\n","\n","# specify name of input/output file\n","\n","file_name = \"output_0\"\n","\n","\n","import ast\n","\n","input_file = open(transcription_folder + file_name + '.txt', 'r')\n","\n","json_list = []\n","\n","for line in input_file:\n","\n","  # Process each line of the input file through the OpenAI api\n","  output = classify(line)\n","\n","  # The output is a str and we need to reformat as list[Dict]\n","  try:\n","    # Transform the string into a list\n","    output_list = ast.literal_eval(output)\n","    # Check if the format is a list of dicts, otherwise don't append it\n","    if isinstance(output_list, list) and all(isinstance(item, dict) for item in output_list):\n","      json_format = {\n","          \"text\": line,\n","          \"entities\": ast.literal_eval(output) \n","      }\n","      json_list.append(json_format)\n","\n","  except:\n","        # for some examples, json is not correctly formatted\n","        json_format = {\n","          \"text\": line,\n","          \"entities\": [] # empty list\n","        }\n","\n","input_file.close()\n","\n","# Store the list of dicts in a json file\n","with open(json_folder + file_name + '.json', 'w') as f:\n","    json.dump(json_list, f)\n"],"metadata":{"id":"fTP7ktnDi_0x","executionInfo":{"status":"ok","timestamp":1680859069238,"user_tz":-60,"elapsed":632464,"user":{"displayName":"Sergio Perez","userId":"07187495172449483138"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["How many samples are there in the json file? What are the entities of the first sentence?"],"metadata":{"id":"LLnGlfbs-TIs"}},{"cell_type":"code","source":["with open(json_folder + file_name + '.json', 'r') as f:\n","    data = json.load(f)\n","\n","\n","print(f'There are {len(data)} sentences in the json file')\n","print(f'The entities of the first sentence are {data[35][\"entities\"]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4toI3_N3sQA6","executionInfo":{"status":"ok","timestamp":1680859581573,"user_tz":-60,"elapsed":228,"user":{"displayName":"Sergio Perez","userId":"07187495172449483138"}},"outputId":"6b895337-f37a-40b1-c9fb-2387686d2e6f"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 42 sentences in the json file\n","The entities of the first sentence are [{'class': 'places', 'text': 'Arendt'}, {'class': 'people', 'text': 'Chanel'}]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Gg30q-o3_L0F"},"execution_count":null,"outputs":[]}]}