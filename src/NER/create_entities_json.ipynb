{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1shnZb2uafo56jVujryiXKovd8mrqDLUx","authorship_tag":"ABX9TyOlrC14HErpNbg+fCqvMeYD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Start installing openai:"],"metadata":{"id":"fPKHjoA8incv"}},{"cell_type":"code","source":["%pip install openai\n","import json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vbp_UIRmkFfE","executionInfo":{"status":"ok","timestamp":1679863229245,"user_tz":-60,"elapsed":9944,"user":{"displayName":"Sergio Perez","userId":"07187495172449483138"}},"outputId":"bf404655-8178-4163-9baa-b9d97791b25d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.2)\n","Collecting argilla\n","  Downloading argilla-1.5.0-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n","Requirement already satisfied: pydantic>=1.7.1 in /usr/local/lib/python3.9/dist-packages (from argilla) (1.10.7)\n","Collecting monotonic\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Collecting rich<=13.0.1\n","  Downloading rich-13.0.1-py3-none-any.whl (238 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.9/dist-packages (from argilla) (1.22.4)\n","Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from argilla) (1.4.4)\n","Collecting deprecated~=1.2.0\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from argilla) (23.0)\n","Collecting backoff\n","  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Collecting httpx<0.24,>=0.15\n","  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wrapt<1.15,>=1.13\n","  Downloading wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n","  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from httpx<0.24,>=0.15->argilla) (2022.12.7)\n","Collecting sniffio\n","  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n","Collecting httpcore<0.17.0,>=0.15.0\n","  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas<2.0.0,>=1.0.0->argilla) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas<2.0.0,>=1.0.0->argilla) (2.8.2)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.7.1->argilla) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich<=13.0.1->argilla) (2.14.0)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n","Collecting h11<0.15,>=0.13\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting anyio<5.0,>=3.0\n","  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.0.0->argilla) (1.16.0)\n","Installing collected packages: rfc3986, monotonic, commonmark, wrapt, sniffio, rich, h11, backoff, deprecated, anyio, httpcore, httpx, argilla\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.15.0\n","    Uninstalling wrapt-1.15.0:\n","      Successfully uninstalled wrapt-1.15.0\n","  Attempting uninstall: rich\n","    Found existing installation: rich 13.3.2\n","    Uninstalling rich-13.3.2:\n","      Successfully uninstalled rich-13.3.2\n","Successfully installed anyio-3.6.2 argilla-1.5.0 backoff-2.2.1 commonmark-0.9.1 deprecated-1.2.13 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 monotonic-1.6 rfc3986-1.5.0 rich-13.0.1 sniffio-1.3.0 wrapt-1.14.1\n"]}]},{"cell_type":"markdown","source":["Define the prompt to pass to the OpenAI api to perform NER:\n"],"metadata":{"id":"5hIbtpr_o-lk"}},{"cell_type":"code","source":["PROMPT_TEMPLATE = \"\"\"\n","Perform name entity recognition in Spanish. The classes are books, films, videogames, songs, places, dates, topics, organizations and people. The output should follow the format:\n","\n","[{'class': 'people', 'text': \"name of the person\"}, {'class': 'books', 'start': 'name of the book}]\n","\n","Sentence: \n","\n","\"\"\"\n","\n","\n"," "],"metadata":{"id":"5cgopnS3ish-","executionInfo":{"status":"ok","timestamp":1679863668604,"user_tz":-60,"elapsed":232,"user":{"displayName":"Sergio Perez","userId":"07187495172449483138"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","Define a function to call the api of OpenAI:\n"],"metadata":{"id":"hrjje0jYraVF"}},{"cell_type":"code","source":["from json import loads\n","import os\n","import openai\n","\n","# set your api key as ENV, for example with Python: os.environ[\"OPENAI_API_KEY\"] = \"your api key\"\n","os.environ[\"OPENAI_API_KEY\"] = \"put_here_your_key\"\n","openai.api_key = os.getenv(\"OPENAI_API_KEY\") \n","\n","def classify(text):\n","    # build prompt with template and input\n","    prompt = f\"{PROMPT_TEMPLATE}\\n{text}\\n\"\n","    # use create completion template\n","    completion = openai.Completion.create(\n","      model=\"text-davinci-003\",\n","      prompt=prompt,\n","      temperature=0,\n","      max_tokens=512\n","    )\n","    # get first choice text\n","    json_response = completion[\"choices\"][0][\"text\"].strip()\n","\n","    return json_response"],"metadata":{"id":"7Q-eH5WBpKjl","executionInfo":{"status":"ok","timestamp":1679863726418,"user_tz":-60,"elapsed":257,"user":{"displayName":"Sergio Perez","userId":"07187495172449483138"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Define the input and output folders and call the OpenAI api:"],"metadata":{"id":"pZEDaQ8M-A96"}},{"cell_type":"code","source":["\n","\n","# specify folder of input transcriptions\n","\n","transcription_folder = \"/content/drive/MyDrive/hackathon_podcast/data/NER/processed_transcription/\"\n","\n","# specify folder of output jsons\n","\n","json_folder = \"/content/drive/MyDrive/hackathon_podcast/data/NER/json_entity/\"\n","\n","\n","import ast\n","\n","input_file = open(transcription_folder + 'output_0.txt', 'r')\n","\n","json_list = []\n","\n","for line in input_file:\n","\n","  # Process each line of the input file through the OpenAI api\n","  output = classify(line)\n","\n","  # The output is a str and we need to reformat as list[Dict]\n","  try:\n","    # Transform the string into a list\n","    output_list = ast.literal_eval(output)\n","    # Check if the format is a list of dicts, otherwise don't append it\n","    if isinstance(output_list, list) and all(isinstance(item, dict) for item in output_list):\n","      json_format = {\n","          \"text\": line,\n","          \"entities\": ast.literal_eval(output) \n","      }\n","      json_list.append(json_format)\n","\n","  except:\n","        # for some examples, json is not correctly formatted\n","        json_format = {\n","          \"text\": line,\n","          \"entities\": [] # empty list\n","        }\n","\n","input_file.close()\n","\n","# Store the list of dicts in a json file\n","with open(json_folder + 'output_0.json', 'w') as f:\n","    json.dump(json_list, f)\n"],"metadata":{"id":"fTP7ktnDi_0x","executionInfo":{"status":"ok","timestamp":1679863779608,"user_tz":-60,"elapsed":43324,"user":{"displayName":"Sergio Perez","userId":"07187495172449483138"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["How many samples are there in the json file? What are the entities of the first sentence?"],"metadata":{"id":"LLnGlfbs-TIs"}},{"cell_type":"code","source":["with open(json_folder + 'output_0.json', 'r') as f:\n","    data = json.load(f)\n","\n","\n","print(f'There are {len(data)} sentences in the json file')\n","print(f'The entities of the first sentence are {data[0][\"entities\"]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4toI3_N3sQA6","executionInfo":{"status":"ok","timestamp":1679868889389,"user_tz":-60,"elapsed":209,"user":{"displayName":"Sergio Perez","userId":"07187495172449483138"}},"outputId":"eba1a410-1f56-41cf-eb9d-1d4c9664d121"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 37 sentences in the json file\n","The entities of the first sentence are [{'class': 'people', 'text': 'Katie Hesel'}, {'class': 'books', 'text': 'Historia del arte sin hombres'}]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Gg30q-o3_L0F"},"execution_count":null,"outputs":[]}]}